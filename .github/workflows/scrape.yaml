name: "Scrape"

on:
  workflow_dispatch:
  schedule:
    - cron: "0 18 * * *"

jobs:
  scrape:
    name: Scrape
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Install Python dependencies
        run: pip install -r requirements.txt
        shell: bash

      - name: Fetch inspection list
        run: python scripts/00-fetch-inspection-list.py
        shell: bash

      - name: Refresh inspection list
        run: python scripts/01-refresh-inspection-list.py
        shell: bash

      - name: Download inspection PDFs
        run: python scripts/02-download-inspection-pdfs.py
        shell: bash

      - name: Parse inspection PDFs
        run: python scripts/03-parse-inspection-pdfs.py
        shell: bash

      - name: Upload inspection PDFs to DocumentCloud
        run: python scripts/04-upload-inspection-pdfs.py
        shell: bash
        env:
          DOCUMENTCLOUD_PROJECT_ID: 211004 
          DOCUMENTCLOUD_USER: ${{ secrets.DOCUMENTCLOUD_USER }}
          DOCUMENTCLOUD_PASSWORD: ${{ secrets.DOCUMENTCLOUD_PASSWORD }}

      - name: Combine data obtained in the previous steps
        run: python scripts/05-combine-inspection-data.py
        shell: bash

      - name: Update RSS
        run: python scripts/06-update-rss.py
        shell: bash

      - name: Config git
        run: git config --global user.email "actions@users.noreply.github.com" && git config --global user.name "Automated"
        shell: bash

      - name: Commit changes
        run: git add data pdfs && (git diff --cached --quiet || git commit -m "Fetch newly available reports")
        shell: bash

      - name: Push changes
        run: git push
        shell: bash

  mirror:
    name: Mirror
    runs-on: ubuntu-latest
    needs: scrape
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Fetch latest commit
        run: git pull origin main
        shell: bash

      - name: Upload inspections CSV to biglocalnews.org
        uses: biglocalnews/upload-files@v2
        with:
          api-key: ${{ secrets.BLN_API_KEY }}
          project-id: ${{ secrets.BLN_PROJECT_ID }}
          path: ./data/fetched/inspections.csv
